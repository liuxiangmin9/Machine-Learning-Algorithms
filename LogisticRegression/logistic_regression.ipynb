{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逻辑斯蒂回归模型可用于二分类或多分类。二分类时，p(y=1|x)=sigmoid(x)=1/(1+exp(-w*x)),p(y=0|x)=1-p(y=1|x)\n",
    "# 可以用极大似然估计法估计模型权重系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入IMDB电影评论数据做二分类\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=1000)     #  保留训练数据中前1000 个最常出现的单词\n",
    "\n",
    "# 填充列表，使其具有相同的长度，做one-hot编码\n",
    "def vectorize_sequences(sequences, dimension=1000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n",
      "(25000,)\n",
      "(25000, 1000)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(train_labels.shape)\n",
    "print(x_test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义逻辑斯蒂分布的分布函数,即sigmoid函数\n",
    "from math import exp\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给各样本加上特征1，以使截距b包含在w中\n",
    "from tqdm import tqdm\n",
    "\n",
    "def data_matrix(X):\n",
    "    data_mat = []\n",
    "    for d in tqdm(X):\n",
    "        data_mat.append([1.0, *d])\n",
    "    return data_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 25000/25000 [00:01<00:00, 22750.13it/s]\n"
     ]
    }
   ],
   "source": [
    "data_mat = data_matrix(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重w\n",
    "weights = np.zeros((len(data_mat[0]), 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:46<00:00,  4.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# 迭代max_epochs次，使用单个样本对权重做梯度上升更新\n",
    "max_epochs = 10\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    for i in range(len(data_mat)):\n",
    "        result = sigmoid(np.dot(data_mat[i], weights))\n",
    "        error = train_labels[i] - result\n",
    "        weights += learning_rate * error * np.transpose([data_mat[i]])          # 似然函数的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "def lr_predict(x_test):\n",
    "    result = []\n",
    "    for i in range(len(x_test)):\n",
    "        temp = np.dot(x_test[i], weights)\n",
    "        if temp>=0:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 25000/25000 [00:01<00:00, 17018.34it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test1 = data_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lr_predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "def accuracy(y, y_pred):\n",
    "    right = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]:\n",
    "            right += 1\n",
    "    return right / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy(test_labels, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84976\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
